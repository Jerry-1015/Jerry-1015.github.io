<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>02类Unix系统目录</title>
    <url>/2022/05/02/02%E7%B1%BBUnix%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95/</url>
    <content><![CDATA[<p>Linux系统中 "所见皆文件"</p>
<p>bin: 存放二进制可执行文件</p>
<p>boot: 存放开机启动程序，相当于Windows的服务</p>
<p>dev: 存放设备文件: 字符设备、块设备</p>
<p>home: 存放用户</p>
<p>etc: 用户信息和系统配置文件</p>
<p>lib: 库文件：lib.so.6</p>
<p>root: 管理员宿主目录</p>
<p>usr: 用户资源管理目录</p>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>03目录和文件操作1</title>
    <url>/2022/05/02/03%E7%9B%AE%E5%BD%95%E5%92%8C%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C1/</url>
    <content><![CDATA[<h5 id="相对路径和绝对路径">相对路径和绝对路径</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ./home // 当前目录下的home</span><br><span class="line"><span class="built_in">cd</span> .. // 返回上一级</span><br><span class="line"><span class="built_in">cd</span> - // 切回上一个工作目录</span><br><span class="line"><span class="built_in">cd</span> ~ // 进入家目录</span><br></pre></td></tr></table></figure>
<h5 id="ls-命令">ls 命令</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -l // 显示详细信息</span><br><span class="line"><span class="built_in">ls</span> -a // 显示隐藏文件</span><br><span class="line"><span class="built_in">ls</span> -d // 显示目录</span><br><span class="line"><span class="built_in">ls</span> -l <span class="built_in">dir</span> // 显示 <span class="built_in">dir</span> 目录下的文件的详细信息</span><br><span class="line"><span class="built_in">ls</span> -dl <span class="built_in">dir</span> // 显示 <span class="built_in">dir</span> 的详细信息</span><br><span class="line"><span class="built_in">ls</span> -r // 递归，向下显示目录</span><br><span class="line"><span class="built_in">ls</span> -R // 递归，向下显示目录, 大小 r 有区别</span><br></pre></td></tr></table></figure>
<h5 id="linux系统文件类型">linux系统文件类型</h5>
<ul>
<li>普通文件：-</li>
<li>目录文件：d</li>
<li>字符设备文件：c</li>
<li>块设备文件：b</li>
<li>软链接：l</li>
<li>管道文件：p</li>
<li>套接字：s</li>
<li>未知文件</li>
</ul>
<h5 id="which-命令">which 命令</h5>
<blockquote>
<p>查看指定命令所在路径</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">which</span> <span class="built_in">ls</span></span><br><span class="line"><span class="built_in">which</span> data</span><br></pre></td></tr></table></figure>
<h5 id="pwd-命令">pwd 命令</h5>
<blockquote>
<p>查看当前所在路径</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">pwd</span></span><br></pre></td></tr></table></figure>
<h5 id="mkdir-命令">mkdir 命令</h5>
<blockquote>
<p>创建目录</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> dir1 dir2 // 一次创建多个目录</span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">dir</span>/dir1/dir2 // 连同父目录一同创建</span><br></pre></td></tr></table></figure>
<h5 id="rmdir-命令">rmdir 命令</h5>
<blockquote>
<p>删除空目录</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rmdir</span> dir1</span><br><span class="line"><span class="built_in">rmdir</span> -p a/b // 连同空的父目录一起删除</span><br></pre></td></tr></table></figure>
<h5 id="touch-命令">touch 命令</h5>
<blockquote>
<p>创建空文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">touch</span> hello.c</span><br></pre></td></tr></table></figure>
<h5 id="rm-命令">rm 命令</h5>
<blockquote>
<p>删除文件、目录</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> file // 删除文件</span><br><span class="line"><span class="built_in">rm</span> <span class="built_in">dir</span> -rf // 删除目录 f：强制删除</span><br></pre></td></tr></table></figure>
<h5 id="mv-命令">mv 命令</h5>
<blockquote>
<p>移动文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> <span class="built_in">source</span> destination </span><br></pre></td></tr></table></figure>
<h5 id="cp-命令">cp 命令</h5>
<blockquote>
<p>拷贝文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> hello.c <span class="built_in">dir</span></span><br><span class="line"><span class="built_in">cp</span> hello.c hello.cpp // 用hello.c 创建 hello.cpp</span><br><span class="line"><span class="built_in">cp</span> hello.* <span class="built_in">dir</span></span><br><span class="line"><span class="built_in">cp</span> <span class="built_in">dir</span> .. // 显示 路过目录<span class="string">&quot;dir&quot;</span></span><br><span class="line"><span class="built_in">cp</span> <span class="built_in">dir</span> -a <span class="built_in">dir</span> .. // 全部拷贝 包括文件属性 时间、权限等</span><br><span class="line"><span class="built_in">cp</span> <span class="built_in">dir</span> -r <span class="built_in">dir</span> .. // </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>07查找与检索</title>
    <url>/2022/05/05/07%E6%9F%A5%E6%89%BE%E4%B8%8E%E6%A3%80%E7%B4%A2/</url>
    <content><![CDATA[<div class="note primary no-icon"><h5 id="find-命令">find 命令</h5>
<p><code>查找</code> - -type 按文件类型搜索 d/p/s/c/b/l/f - -name
按文件名搜索 - -maxdepth 指定搜索深度 - -size 按文件大小搜索，单位 k, M,
G - -atime 按 access 的时间 - -mtime 按 modify 的时间 - -ctime 按 change
的时间</p>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find ./ -<span class="built_in">type</span> <span class="string">&#x27;l&#x27;</span></span><br><span class="line">find ./ -name <span class="string">&#x27;*.cc&#x27;</span></span><br><span class="line">find ./ -maxdepth 1 -name <span class="string">&#x27;*.cc&#x27;</span>  // 参数有顺序要求</span><br><span class="line">find ./ -size +20M -size -50M</span><br><span class="line">find ./ -ctime 1</span><br></pre></td></tr></table></figure>
<div class="note primary no-icon"><h5 id="grep-命令">grep 命令</h5>
</div>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>06创建修改用户和用户组</title>
    <url>/2022/05/04/06%E5%88%9B%E5%BB%BA%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84/</url>
    <content><![CDATA[<h5 id="whoami-命令">whoami 命令</h5>
<blockquote>
<p>查看当前用户</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">whoami</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/OCRfrmtYsBq4DA5.png" /></p>
<div class="note "><h5 id="chmod-命令">chmod 命令</h5>
<ul>
<li>chmod [who][+|-|=][mode] 文件名</li>
<li>[who]:</li>
<li>u 表示用户(user), 即文件或目录所有者</li>
<li>g 表示同组(group)用户， 即与文件属组有相同组ID的所有用户</li>
<li>o 表示其他(others)用户</li>
<li>a 表示所有(all)用户，它是系统默认值 数字设定：r: 4; w: 2; x:
1。</li>
</ul>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> u+x hello.cc</span><br><span class="line"><span class="built_in">chmod</span> g-r hello.cc</span><br><span class="line"><span class="built_in">chmod</span> o+w hello.cc</span><br><span class="line"><span class="built_in">chmod</span> a+r hello.cc</span><br><span class="line"><span class="built_in">chmod</span> 471 hello.cc</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/3tgyU2rDCRTbWA8.png" /></p>
<h5 id="chown-命令">chown 命令</h5>
<blockquote>
<p>修改文件或目录的所有者或所属组</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> wangwu hello.cc</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/xgOX1HhsraEK3CD.png" /></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chgrp</span> g88 hello.cc</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/DheubWI6CSR975l.png" /></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chown</span> nobody:nogroup hello.cc</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/05/Yf45k8iA6WlnyP3.png" /></p>
<h5 id="adduser-addgroup-命令">adduser addgroup 命令</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo adduser wangwu</span><br><span class="line">sudo addgroup g88</span><br></pre></td></tr></table></figure>
<h5 id="deluser-delgroup-命令">deluser delgroup 命令</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deluser wangwu</span><br><span class="line">delgroup g88</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>04目录和文件操作2</title>
    <url>/2022/05/03/04%E7%9B%AE%E5%BD%95%E5%92%8C%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C2/</url>
    <content><![CDATA[<h5 id="cat-命令">cat 命令</h5>
<blockquote>
<p>查看文件内容、读终端</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> hello.cc // 查看文件内容</span><br><span class="line"><span class="built_in">cat</span> // 回显终端</span><br><span class="line"><span class="built_in">tac</span> hello.cc // 文件内容倒着显示</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/03/hfjvTVn5ZMCkqaJ.png" /></p>
<h5 id="more-less命令">more less命令</h5>
<blockquote>
<p>分屏显示 空格翻页，回车一行，退出用q</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">more stdio.h</span><br><span class="line">less stdio.h</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/G7SFDYOXKRAdWnj.png" /></p>
<h5 id="head-tail-命令">head tail 命令</h5>
<blockquote>
<p>显示默认前10行、显示默认后10行</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">head</span> stdio.h</span><br><span class="line"><span class="built_in">head</span> -5 stdio.h</span><br><span class="line"><span class="built_in">tail</span> -15 stdio.h</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/IeGijw3v4OV5yKa.png" /></p>
<h5 id="tree-命令">tree 命令</h5>
<blockquote>
<p>以树状形式显示文件</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/05/04/nUZvuWgPehkCTwp.png" /></p>
<h5 id="wc-命令">wc 命令</h5>
<blockquote>
<p>计算文件的byte数，字数，或是列数</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">wc</span> -c hello.cc // 只显示byte数</span><br><span class="line"><span class="built_in">wc</span> -l hello.cc // 只显示列数</span><br><span class="line"><span class="built_in">wc</span> -w hello.cc // 只显示字数</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/04/Ih1mjx6MvWRUw8N.png" /></p>
<h5 id="od-命令">od 命令</h5>
<blockquote>
<p>查看当前文件的不同数据的显示</p>
</blockquote>
<h5 id="du-df-命令">du df 命令</h5>
<blockquote>
<p>du： 显示某个目录大小； df：查看磁盘剩余空间</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>05软链接和硬链接</title>
    <url>/2022/05/04/05%E8%BD%AF%E9%93%BE%E6%8E%A5%E5%92%8C%E7%A1%AC%E9%93%BE%E6%8E%A5/</url>
    <content><![CDATA[<h5 id="ln-命令">ln 命令</h5>
<blockquote>
<p>创建链接</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s file file.s</span><br><span class="line"><span class="built_in">ln</span> -s ./file file.soft</span><br></pre></td></tr></table></figure>
<p><strong>软链接功能相当于Windows下的快捷方式</strong></p>
<ol type="1">
<li><p>file.s 文件的大小为4个字节 4个字节的内容为file的访问路径 <img
src="https://s2.loli.net/2022/05/04/E7AcoanMZeRvLj8.png" /></p></li>
<li><p>file.soft 文件的大小为6个字节 因为利用 <code>./</code> +
文件名方式创建，所以有差异 <img
src="https://s2.loli.net/2022/05/04/nWATK2EqVzspClM.png" /></p></li>
<li><p>利用相对路径创建的软链接，移动到别的目录下不能正确执行，若想顺利执行，需要使用绝对路径</p></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /home/jerry/file file.s2</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>为保证软链接可以任意搬移，创建时务必使用绝对路径</li>
<li>软链接的权限全开放，代表软链接本身的权限，不是文件的权限</li>
</ol>
<p><strong>硬链接对任意一个文件进行修改，其他文件都会发生变化</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> file file.h</span><br><span class="line"><span class="built_in">ln</span> file file.hard</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>如何实现？</li>
<li>Inode实现：给每个文件赋一个数</li>
<li>三个文件有相同的Inode</li>
<li>当操作任意一个文件时，都是操作同一个Inode的文件</li>
<li>删除的时候怎么办？都删？实际上并不是</li>
<li>而是并没有真正删除，只是把硬链接计数减一，当硬链接计数为0时，才真正删除文件</li>
<li>操作系统给每一个文件赋予唯一的Inode，当有相同Inode文件存在时，彼此同步。</li>
<li>删除时，只将硬链接计数减一， 减为0时，Inode释放</li>
</ol>
]]></content>
      <categories>
        <category>Linux系统编程</category>
      </categories>
      <tags>
        <tag>Linux常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title>BP神经网络</title>
    <url>/2022/05/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="bp神经网络算法">BP神经网络算法</h1>
<h4 id="算法原理">1. 算法原理</h4>
<h5 id="概述">1.1 概述</h5>
<p>​ <strong>人工神经网络</strong>无需事先确定输入输出之间<a
href="">映射关系</a>的数学方程，仅通过自身的训练，学习某种规则，在给定输入值时得到最接近期望输出值的结果。作为一种智能信息处理系统，人工神经网络实现其功能的核心是算法。BP神经网络是一种按==误差反向传播==(简称误差反传)训练的多层前馈网络，其算法称为<a
href="https://baike.baidu.com/item/BP算法">BP算法</a>，它的基本思想是==梯度下降法==，利用梯度搜索技术，以期使网络的实际输出值和期望输出值的误差均方差为最小。
​ <strong>BP神经网络的计算过程</strong>由<a href="">正向计算过程</a>和<a
href="">反向计算过程</a>组成。正向传播过程，输入模式从输入层经隐单元层逐层处理，并转向输出层，每一层神经元的状态只影响下一层神经元的状态。如果在输出层不能得到期望的输出，则转入反向传播，将误差信号沿原来的连接通路返回，通过修改各神经元的权值，使得误差信号最小。</p>
<h5 id="算法分析">1.2 算法分析</h5>
<p><strong>多层神经网络结构</strong>：</p>
<p><img src="https://s2.loli.net/2022/05/01/tv5mA6lQ3fjWdIJ.png" style="zoom: 50%;" /></p>
<p>通常一个多层神经网络由<span
class="math inline">\(L\)</span>​​层神经元组成，第一层称作==输入层==，最后一层称作==输出层==，中间层为==隐含层==。</p>
<p>多层神经网络的基本组成元素是神经元，单个神经元的模型如下：</p>
<p><img src="https://s2.loli.net/2022/05/01/bvtRcPUYwxQ8A9O.png" alt="image-20210803202615457" style="zoom:50%;" /></p>
<p>输入层输入向量:<span
class="math inline">\(X=(x_1,x_2,...，x_i,...,x_m);\)</span>​</p>
<p>第<span class="math inline">\(l\)</span>​​​​​层的隐含层向量：<span
class="math inline">\(H^l=(h_1^l,h_2^l,...,h_j^l,...,h_{s_l}^l)
(l=2,3,...,L-1,j=1,2,...,s_l);\)</span>​​​​</p>
<p>输出层输出向量：<span
class="math inline">\(Y=(y_1,y_2,...,y_k,...,y_n);\)</span>​</p>
<p>设<span class="math inline">\(w_{ij}^l\)</span>为从第<span
class="math inline">\(l-1\)</span>层的第<span
class="math inline">\(i\)</span>个神经元与第<span
class="math inline">\(l\)</span>层的第<span
class="math inline">\(j\)</span>​个神经元之间的连接权重，<span
class="math inline">\(b_j^l\)</span>为第<span
class="math inline">\(l\)</span>层第<span
class="math inline">\(j\)</span>​个神经元的偏置。</p>
<p>因此得到：</p>
<p><span class="math display">\[
\begin{align}
  h_j^l &amp;=f(net_j^l) \nonumber \\
  net_j^l &amp;=\sum_{j=1}^{s_{l-1}}{w_{ij}^l+b_j^l} \nonumber
\end{align}
\]</span></p>
<p>其中<span class="math inline">\(net_j^l\)</span>为第<span
class="math inline">\(l\)</span>层第<span
class="math inline">\(j\)</span>个神经元的输入，<span
class="math inline">\(f(\cdot)\)</span>​为激活函数。</p>
<p><strong>激活函数</strong>：</p>
<blockquote>
<p>作用：引入非线性因素，使得模型能够较好地逼近非线性函数。</p>
</blockquote>
<p>BP神经网络算法常用的激活函数：</p>
<ul>
<li><p>Sigmod函数： <span class="math display">\[
f(x)=\frac{1}{1+e^x}
\]</span>
<img src="https://s2.loli.net/2022/05/01/gNu3h27ljwTPb6i.png" alt="image-20210804000024960" style="zoom: 15%;" /></p></li>
<li><p>Tanh函数（双曲正切函数） <span class="math display">\[
f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\]</span></p>
<p><img src="https://s2.loli.net/2022/05/01/c6aAzTXWSi5V1hj.png" alt="image-20210804001057704" style="zoom:15%;" /></p>
<p><strong>偏置</strong>：</p>
<blockquote>
<p>作用：可以理解为加入一个与输入<span
class="math inline">\(X\)</span>无关的常数项，使得逼近的效果更好。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/05/01/x7pbY5DIjO9AfNh.png" alt="img" style="zoom:50%;" /></p>
<p>如果用<span
class="math inline">\(y=x\)</span>​​​去逼近，效果不如人意，相反如果加入一个常数项，使得<span
class="math inline">\(y=x+2\)</span>​，效果则会好很多。</p>
<p><img src="https://s2.loli.net/2022/05/01/FUqSAPzNbrQIdvi.png" alt="img" style="zoom:50%;" /></p>
<p><strong>误差函数</strong>:</p>
<blockquote>
<p>作用：衡量输出结果与期望输出的差距</p>
</blockquote>
<p>假设有<span class="math inline">\(p\)</span>​个训练样本<span
class="math inline">\(\{(x(1),y(1)),(x(2),y(2)),...,(x(p),y(p))\}\)</span>​,<span
class="math inline">\(d(i)\)</span>​为对应<span
class="math inline">\(x(i)\)</span>​的期望输出，假设单个训练样本有<span
class="math inline">\(n\)</span>​个输出。定义误差函数： <span
class="math display">\[
E=\frac{1}{p}\sum_{i=1}^p{E(i)}
\]</span> 其中<span
class="math inline">\(E(i)\)</span>为单个样本的训练误差： <span
class="math display">\[
E(i)=\frac{1}{2}\sum_{k=1}^n(d_k(i)-y_k(i))^2
\]</span> 因此全局误差函数： <span class="math display">\[
E=\frac{1}{2p}\sum_{i=1}^p\sum_{k=1}^n{(d_k(i)-y_k(i))^2}
\]</span></p>
<p><strong>如何更新权重与偏置</strong>：</p>
<blockquote>
<p>误差反向传播更新权重与偏置</p>
</blockquote>
<p>一般采用梯度下降法更新权重与偏置： <span class="math display">\[
w_{ij}^l=w_{ij}^l-\alpha \frac{\partial E}{\partial w_{ij}^l} \\
b_{j}^l=b_j^l-\alpha \frac{\partial E}{\partial b_j^l}
\]</span></p>
<p>其中$<span
class="math inline">\(​为学习速率，\)</span>(0,1)$​​。BP神经网络算法关键就在与如何求解上述两个偏导数，具体推导比较繁杂，这里就不在叙述，相关参考将附在文末<a
href="#第二种跳转"><sup>2</sup></a>。</p></li>
</ul>
<h5 id="回顾">1.3 回顾</h5>
<p>最后我们再通过一个示意图，回顾BP神经网络算法的整个流程。</p>
<p><img src="https://s2.loli.net/2022/05/01/wIgxHEAbeLjPBmN.png" alt="image-20210804155659704" style="zoom: 67%;" /></p>
<h5 id="优劣势">1.4 优劣势</h5>
<p><strong>优势</strong>：</p>
<p>主要用于以下四个方面：</p>
<ul>
<li>函数逼近</li>
<li>模式识别</li>
<li>分类</li>
<li>数据压缩</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>学习速度慢，需要多次学习才能收敛</li>
<li>采用梯度下降法，容易陷入局部最小值</li>
<li>网络层数、神经元个数的选取没有理论指导，主要凭借经验</li>
<li>网络推广能力有限</li>
</ul>
<h4 id="matlab实现">2. Matlab实现</h4>
<h5 id="算法实现步骤">2.1 算法实现步骤</h5>
<ol type="1">
<li><p>进行数据预处理</p></li>
<li><p>建立BP神经网络模型</p></li>
<li><p>利用样本进行训练</p></li>
<li><p>返回训练结束的模型</p></li>
</ol>
<h5 id="案例">2.2 案例</h5>
<p>​
在建立BP神经网络模型以及训练（即更新权重与偏置）Matlab有自带的函数，在实现BP神经网络算法的时候，我们直接调用这些函数就可以。</p>
<p>​
为了能够更清晰地了解算法的实现过程，这里选取比较简单的数据进行演示。</p>
<p><strong>案例一</strong>：曲线拟合</p>
<p>题目：创建BP神经网络</p>
<p>输入向量 <span
class="math inline">\(P=[0,1,2,3,4,5,6,7,8,9,10];\)</span></p>
<p>期望输出 <span
class="math inline">\(T=[0,1,2,3,4,3,2,1,2,3,4];\)</span></p>
<p>散点图如下：</p>
<p><img src="https://s2.loli.net/2022/05/01/t15rSj4P9Ibzulw.png" alt="img" style="zoom:50%;" /></p>
<p>试用BP神经网络算法对上图进行拟合，并将拟合效果绘图展示。</p>
<p><strong>Matlab代码</strong>：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">close all; clearvars; clear; <span class="comment">%清空工作环境</span></span><br><span class="line">P = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>];</span><br><span class="line">T = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>];</span><br><span class="line"><span class="comment">%由于feedforwardnet函数自动对样本进行归一化和划分训练、验证、测试集,</span></span><br><span class="line"><span class="comment">%所以就不用手动将数据进行归一化处理，但不知道有没有打乱顺序</span></span><br><span class="line"><span class="comment">% n=size(P,2); temp=randperm(n); P_train=P(temp(1:8));</span></span><br><span class="line"><span class="comment">% T_train=T(temp(1:8)); P_test=P(temp(9:end)); T_test=T(temp(9:end));</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% [p_train,p_input]=mapminmax(P_train,0,1);</span></span><br><span class="line"><span class="comment">% [t_train,t_output]=mapminmax(T_train,0,1);</span></span><br><span class="line"><span class="comment">% p_test=mapminmax(P_test,p_input);</span></span><br><span class="line">net = feedforwardnet(<span class="number">5</span>, <span class="string">&#x27;traingd&#x27;</span>); </span><br><span class="line"><span class="comment">%是&#x27;5&#x27;是指隐含层有5个神经元，这里只有一个隐含层，多个隐含层神经元的个数设置为[5,3,...]</span></span><br><span class="line"></span><br><span class="line">net.trainParam.lr = <span class="number">0.01</span>; <span class="comment">%学习速率</span></span><br><span class="line">net.trainParam.epochs = <span class="number">10000</span>; <span class="comment">%最大训练次数</span></span><br><span class="line">net.trainParam.goal = <span class="number">1e-6</span>; <span class="comment">%最小误差，达到该精度，停止训练</span></span><br><span class="line">net.trainParam.show = <span class="number">50</span>; <span class="comment">%每50次展示训练结果</span></span><br><span class="line">net = train(net, P, T); <span class="comment">%训练</span></span><br><span class="line">Y = net(P); <span class="comment">%输出</span></span><br><span class="line">perf = perform(net, Y, T);<span class="comment">%误差</span></span><br><span class="line"><span class="built_in">plot</span>(P, T, P, Y, <span class="string">&#x27;r-&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>结果还不错的几个图</strong>：</p>
<p><img src="https://s2.loli.net/2022/05/01/6jYC8JGF3tHpurM.png" style="zoom:45%;" /></p>
<p><img src="https://s2.loli.net/2022/05/01/gkDKQJurA8mPq4X.png" alt="2" style="zoom:45%;" /></p>
<p><img src="https://s2.loli.net/2022/05/01/xDOQSFgGa8sjXVh.png" alt="3" style="zoom:45%;" />
<img src="https://s2.loli.net/2022/05/01/bmi67HagVJpDzKd.png" alt="4" style="zoom:45%;" /></p>
<p>由于训练的样本太少，所以结果不是很令人满意。</p>
<p><strong>案例二</strong>：蠓虫分类</p>
<p>题目：依据的资料是触角和翅膀的长度，已经测得了9 支Af 和6 支Apf
的数据如下： Af:
(1.24,1.72)，(1.36,1.74)，(1.38,1.64)，(1.38,1.82)，(1.38,1.90)，(1.40,1.70)，
(1.48,1.82)，(1.54,1.82)，(1.56,2.08). Apf:
(1.14,1.78)，(1.18,1.96)，(1.20,1.86)，(1.26,2.00)，(1.28,2.00)，(1.30,1.96).</p>
<p>试对触角和翼长分别为(1.24,1.80)，(1.28,1.84)与(1.40,2.04)的3
个标本加以识别。</p>
<p><strong>Matlab代码</strong>：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clearvars; close all; <span class="comment">%清空工作环境</span></span><br><span class="line"><span class="comment">%导入数据，第一列为触角长度，第二列为翅膀长度</span></span><br><span class="line">x_1 = [<span class="number">1.24</span>, <span class="number">1.72</span>; <span class="number">1.36</span>, <span class="number">1.74</span>; <span class="number">1.38</span>, <span class="number">1.64</span>; <span class="number">1.38</span>, <span class="number">1.82</span>;</span><br><span class="line">    <span class="number">1.38</span>, <span class="number">1.90</span>; <span class="number">1.40</span>, <span class="number">1.70</span>; <span class="number">1.48</span>, <span class="number">1.82</span>; <span class="number">1.54</span>, <span class="number">1.82</span>; <span class="number">1.56</span>, <span class="number">2.08</span>]; <span class="comment">%Af蠓虫</span></span><br><span class="line">x_2 = [<span class="number">1.14</span>, <span class="number">1.78</span>; <span class="number">1.18</span>, <span class="number">1.96</span>; <span class="number">1.20</span>, <span class="number">1.86</span>; <span class="number">1.26</span>, <span class="number">2.00</span>; <span class="number">1.28</span>, <span class="number">2.00</span>;</span><br><span class="line">    <span class="number">1.30</span>, <span class="number">1.96</span>]; <span class="comment">%Apf蠓虫</span></span><br><span class="line">x = [x_1; x_2]&#x27;; <span class="comment">%合并转置，因为feedforwardnet函数以一列为单个样本</span></span><br><span class="line"></span><br><span class="line">goal = [<span class="built_in">ones</span>(<span class="number">1</span>, <span class="number">9</span>), <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="number">6</span>); <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="number">9</span>), <span class="built_in">ones</span>(<span class="number">1</span>, <span class="number">6</span>)]; <span class="comment">%(1,0)表示为</span></span><br><span class="line"><span class="comment">%Af蠓虫，(0,1)表示Apf蠓虫</span></span><br><span class="line">x_recognize = [<span class="number">1.24</span>, <span class="number">1.80</span>; <span class="number">1.28</span>, <span class="number">1.84</span>; <span class="number">1.40</span>, <span class="number">2.04</span>]&#x27;; <span class="comment">%识别的样本</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>(x_1(:, <span class="number">1</span>), x_1(:, <span class="number">2</span>), <span class="string">&#x27;ro&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;Af&#x27;</span>); <span class="comment">%绘制Af的散点图</span></span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(x_2(:, <span class="number">1</span>), x_2(:, <span class="number">2</span>), <span class="string">&#x27;bo&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;Apf&#x27;</span>); <span class="comment">%绘制Apf的散点图</span></span><br><span class="line"><span class="built_in">plot</span>(x_recognize(<span class="number">1</span>, :), x_recognize(<span class="number">2</span>, :), <span class="string">&#x27;yo&#x27;</span>, <span class="string">&#x27;DisplayName&#x27;</span>, <span class="string">&#x27;识别&#x27;</span> ); <span class="comment">%绘制识别样本的散点图</span></span><br><span class="line">xlabel(<span class="string">&#x27;触角长度&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;翅膀长度&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>;</span><br><span class="line"></span><br><span class="line">net = feedforwardnet([<span class="number">3</span>, <span class="number">2</span>], <span class="string">&#x27;trainlm&#x27;</span>); <span class="comment">%两层隐含层，相应神经元个数分别为3和2，采用L-M优化算法，效果比较好</span></span><br><span class="line">net.trainParam.max_fail = <span class="number">1000</span>; <span class="comment">%连续1000次误差不下降，停止训练</span></span><br><span class="line">net.trainParam.lr = <span class="number">0.05</span>; <span class="comment">%学习速率</span></span><br><span class="line">net.trainParam.epochs = <span class="number">10000</span>; <span class="comment">%最大训练次数</span></span><br><span class="line">net.trainParam.goal = <span class="number">1e-15</span>; <span class="comment">%最小误差，达到该精度，停止训练</span></span><br><span class="line">net.trainParam.show = <span class="number">50</span>; <span class="comment">%每50次展示训练结果</span></span><br><span class="line">net = train(net, x, goal); <span class="comment">%训练</span></span><br><span class="line">y0 = sim(net, x) <span class="comment">%输出</span></span><br><span class="line">perf = perform(net, goal, y0)<span class="comment">%误差</span></span><br><span class="line">ym = sim(net, x_recognize) <span class="comment">%识别</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>下图是蠓虫的散点图，可以看出这三个样本还是比较难分类的，肉眼几乎很难判断。利用BP神经网络算法得到的结果有时候也会有比较大的差异，这也很正常，仅通过触角和翅膀长度确实不易分辨。</p>
<p><img src="https://s2.loli.net/2022/05/01/KW4w6ZEHdrvGQXM.png" style="zoom:50%;" /></p>
<p>这是训练误差比较低情况下的一个输出，显示识别样本中第一、第二为Af类型的蠓虫，第三为Apf类型的蠓虫。</p>
<figure>
<img src="https://s2.loli.net/2022/05/01/t1WmHSNoKn6BVRx.png"
alt="image-20210804215106236" />
<figcaption aria-hidden="true">image-20210804215106236</figcaption>
</figure>
<h4 id="参考来源"><strong>3. 参考来源</strong></h4>
<p>[1] <a
href="https://baike.baidu.com/item/BP神经网络/4581827">BP神经网络_百度百科
(baidu.com)</a></p>
<p>[2] <a
href="https://www.cnblogs.com/biaoyu/p/4591304.html#!comments">BP神经网络推导过程详解
- Alex Yu - 博客园 (cnblogs.com)</a><a name="第二种跳转"> </a></p>
<p>[3] <a href="https://www.bilibili.com/video/BV1A4411x76J">专题
通过四个matlab建模案例彻底精通BP神经网络_哔哩哔哩_bilibili</a></p>
<p>[4] <a
href="https://www.bilibili.com/video/BV11K4y1h7MD?from=search&amp;seid=8384977427461027422">最容易听懂的BP神经网络教程----萌新入门首选课_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
</search>
